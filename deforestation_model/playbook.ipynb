{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"akhilchibber/deforestation-detection-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib numpy scikit-image rasterio tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import normalize\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset'\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    print(\"Directory:\", root)\n",
    "    print(\"Subdirectories:\", dirs)\n",
    "    print(\"Files:\", files)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deforestation imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to a sample .tif file\n",
    "tif_file = '/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_16_GRID/RASTER_0.tif'\n",
    "\n",
    "# Open and display the image\n",
    "with rasterio.open(tif_file) as src:\n",
    "    image = src.read(1)  # Read the first band\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"Sample .tif Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "with rasterio.open('/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_16_GRID/RASTER_0.tif') as src:\n",
    "    image = src.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inspect the raw file\n",
    "file_path = '/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_16_GRID/RASTER_0.tif'\n",
    "\n",
    "# Load as a memory map to avoid excessive memory usage\n",
    "with open(file_path, 'rb') as f:\n",
    "    raw_data = np.fromfile(f, dtype='float32')  # Adjust dtype based on your file\n",
    "    print(f\"Raw data size: {raw_data.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "array_size = 31724006\n",
    "for i in range(1, int(math.sqrt(array_size)) + 1):\n",
    "    if array_size % i == 0:\n",
    "        print(f\"Possible dimensions: {i} x {array_size // i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bands = array_size // (512 * 512)  # Replace 512 with plausible dimensions\n",
    "print(f\"Number of bands: {num_bands}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import normalize\n",
    "\n",
    "# Paths\n",
    "image_dir = '/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_16_GRID/'\n",
    "mask_dir = '/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/3_TRAINING_MASKS/MASK_16_GRID/'\n",
    "\n",
    "# Parameters\n",
    "IMG_HEIGHT, IMG_WIDTH = 256, 256  # Fixed size for training\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess function\n",
    "def preprocess_image(filepath, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    image = imread(filepath)  # Read image\n",
    "    image = normalize(image, axis=1)  # Normalize to [0, 1]\n",
    "    image = resize(image, target_size, mode='reflect', anti_aliasing=True)  # Resize\n",
    "    return image\n",
    "\n",
    "def preprocess_mask(filepath, target_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    mask = imread(filepath, as_gray=True)  # Read mask (grayscale)\n",
    "    mask = resize(mask, target_size, mode='reflect', anti_aliasing=True)  # Resize\n",
    "    mask = np.round(mask)  # Ensure binary values (0 or 1)\n",
    "    return mask\n",
    "\n",
    "# Load data\n",
    "image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.tif')])\n",
    "mask_files = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.tif')])\n",
    "\n",
    "images = np.array([preprocess_image(f) for f in image_files])\n",
    "masks = np.array([preprocess_mask(f) for f in mask_files])\n",
    "\n",
    "print(f\"Images shape: {images.shape}, Masks shape: {masks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_preprocess_sentinel_image(tif_path, is_mask=False):\n",
    "    \"\"\"\n",
    "    Load and preprocess image/mask\n",
    "    is_mask: boolean to indicate if the file is a mask\n",
    "    \"\"\"\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        if is_mask:\n",
    "            # For masks: load single band and ensure binary values\n",
    "            mask = src.read(1)  # Read first band only\n",
    "            mask = (mask > 0).astype(np.float32)  # Convert to binary (0 and 1)\n",
    "            return mask\n",
    "        else:\n",
    "            # For images: load all 4 bands\n",
    "            image = src.read()\n",
    "            \n",
    "            # Normalize values (based on your data range)\n",
    "            image = image / 6000.0  # Adjust based on your max value (~5794)\n",
    "            \n",
    "            # Transpose to channel-last format (HEIGHT, WIDTH, CHANNELS)\n",
    "            image = np.transpose(image, (1, 2, 0))\n",
    "            \n",
    "            return image\n",
    "\n",
    "def load_dataset(image_dir, mask_dir, image_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Load and preprocess the complete dataset\n",
    "    \"\"\"\n",
    "    # Get file lists\n",
    "    image_files = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.tif')])\n",
    "    mask_files = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.tif')])\n",
    "    \n",
    "    # Lists to store processed data\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    \n",
    "    for img_path, mask_path in zip(image_files, mask_files):\n",
    "        # Load and preprocess image\n",
    "        img = load_and_preprocess_sentinel_image(img_path, is_mask=False)\n",
    "        \n",
    "        # Load and preprocess mask\n",
    "        mask = load_and_preprocess_sentinel_image(mask_path, is_mask=True)\n",
    "        \n",
    "        # Resize if needed\n",
    "        if image_size is not None:\n",
    "            img = tf.image.resize(img, image_size)\n",
    "            mask = tf.image.resize(mask[..., np.newaxis], image_size)\n",
    "        \n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Masks shape: {masks.shape}\")\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "# Example usage\n",
    "def prepare_training_data(image_dir, mask_dir, image_size=(256, 256), val_split=0.2):\n",
    "    \"\"\"\n",
    "    Prepare data for training\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    images, masks = load_dataset(image_dir, mask_dir, image_size=image_size)\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        images, masks, test_size=val_split, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"\\nData split complete:\")\n",
    "    print(f\"Training images shape: {X_train.shape}\")\n",
    "    print(f\"Training masks shape: {y_train.shape}\")\n",
    "    print(f\"Validation images shape: {X_val.shape}\")\n",
    "    print(f\"Validation masks shape: {y_val.shape}\")\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "# Use the functions\n",
    "image_dir = \"/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_16_GRID\"\n",
    "mask_dir = \"/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/3_TRAINING_MASKS/MASK_16_GRID\"\n",
    "\n",
    "# Prepare the data\n",
    "X_train, X_val, y_train, y_val = prepare_training_data(\n",
    "    image_dir, \n",
    "    mask_dir,\n",
    "    image_size=(256, 256),  # Resize images to 256x256\n",
    "    val_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
    "\n",
    "def create_unet(input_shape=(256, 256, 4)):\n",
    "    \"\"\"\n",
    "    Create basic U-Net model\n",
    "    \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # Bridge\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    \n",
    "    # Decoder\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = concatenate([conv2, up1], axis=3)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(up1)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    up2 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up2 = concatenate([conv1, up2], axis=3)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(up2)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    # Output\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = create_unet(input_shape=(256, 256, 4))\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=3)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss during Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy during Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('unet_deforestation_model.h5')\n",
    "\n",
    "# Evaluate\n",
    "results = model.evaluate(X_val, y_val)\n",
    "loss = results[0]\n",
    "accuracy = results[1]\n",
    "print(f\"Validation loss: {loss}, Validation accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation dataset\n",
    "predicted_masks = model.predict(X_val)\n",
    "\n",
    "# Threshold the predictions to get binary masks (0 or 1)\n",
    "threshold = 0.5\n",
    "predicted_masks = (predicted_masks > threshold).astype(np.uint8)\n",
    "\n",
    "print(f\"Predicted masks shape: {predicted_masks.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sample(image, ground_truth, prediction, index):\n",
    "    \"\"\"\n",
    "    Plot a single image with its ground truth mask and predicted mask.\n",
    "    Args:\n",
    "        image: The original image (input to the model).\n",
    "        ground_truth: The ground truth mask (label).\n",
    "        prediction: The predicted mask from the model.\n",
    "        index: Index of the image to visualize.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Original Image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image[index])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Ground Truth Mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.imshow(ground_truth[index], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Predicted Mask\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.imshow(prediction[index], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example: Plot the first sample\n",
    "plot_sample(X_val, y_val, predicted_masks, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_samples(images, ground_truths, predictions, num_samples=5):\n",
    "    \"\"\"\n",
    "    Plot multiple images with their ground truth and predicted masks.\n",
    "    Args:\n",
    "        images: Array of input images.\n",
    "        ground_truths: Array of ground truth masks.\n",
    "        predictions: Array of predicted masks.\n",
    "        num_samples: Number of samples to visualize.\n",
    "    \"\"\"\n",
    "    # Use the minimum of num_samples or the number of available samples\n",
    "    num_samples = min(num_samples, len(images))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        plot_sample(images, ground_truths, predictions, index=i)\n",
    "\n",
    "# Plot the first 5 samples (adjusting for available data size)\n",
    "plot_multiple_samples(X_val, y_val, predicted_masks, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "# Load a sample image and mask\n",
    "sample_image = '/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_16_GRID/RASTER_0.tif'\n",
    "sample_mask = imread('/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/3_TRAINING_MASKS/MASK_16_GRID/RASTER_0.tif')\n",
    "\n",
    "# Plot sample image and mask\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "with rasterio.open(sample_image) as src:\n",
    "    image = src.read(1)  # Read the first band\n",
    "    plt.imshow(image, cmap='gist_earth')\n",
    "    plt.title(\"Sample Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Sample Mask\")\n",
    "plt.imshow(sample_mask, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/home/epele/.cache/kagglehub/datasets/akhilchibber/deforestation-detection-dataset/versions/1/1_CLOUD_FREE_DATASET/2_SENTINEL2/IMAGE_FULL/raster.tif'\n",
    "sample_image = imread(image_path)\n",
    "print(f\"Image shape: {sample_image.shape}\")\n",
    "\n",
    "with rasterio.open(image_path) as src:\n",
    "    image = src.read(1)  # Read the first band\n",
    "    plt.imshow(image, cmap='gist_earth')\n",
    "    plt.title(\"Sample .tif Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definim punctele unui cub în spațiul 3D.\n",
    "# Cubul are o față la z = 3 și cealaltă la z = 5.\n",
    "points = np.array([\n",
    "    [-1, -1, 3],\n",
    "    [ 1, -1, 3],\n",
    "    [ 1,  1, 3],\n",
    "    [-1,  1, 3],\n",
    "    [-1, -1, 5],\n",
    "    [ 1, -1, 5],\n",
    "    [ 1,  1, 5],\n",
    "    [-1,  1, 5]\n",
    "])\n",
    "\n",
    "# Funcția de proiecție simplă: aplică formula x' = (d*x)/z, y' = (d*y)/z.\n",
    "def project(point, d=1):\n",
    "    x, y, z = point\n",
    "    return np.array([d * x / z, d * y / z])\n",
    "\n",
    "# Proiectăm toate punctele cubului.\n",
    "projected_points = np.array([project(p, d=1) for p in points])\n",
    "\n",
    "# Configurăm graficul.\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(projected_points[:,0], projected_points[:,1], color='blue')\n",
    "for i, p in enumerate(projected_points):\n",
    "    plt.text(p[0], p[1], str(i), color='red', fontsize=12)\n",
    "\n",
    "# Definim muchiile cubului pentru a-l desena corect.\n",
    "edges = [\n",
    "    (0,1), (1,2), (2,3), (3,0),  # fața din față\n",
    "    (4,5), (5,6), (6,7), (7,4),  # fața din spate\n",
    "    (0,4), (1,5), (2,6), (3,7)   # muchiile laterale\n",
    "]\n",
    "\n",
    "# Desenăm muchiile cubului.\n",
    "for e in edges:\n",
    "    p1 = projected_points[e[0]]\n",
    "    p2 = projected_points[e[1]]\n",
    "    plt.plot([p1[0], p2[0]], [p1[1], p2[1]], 'k-')\n",
    "\n",
    "plt.xlabel(\"x'\")\n",
    "plt.ylabel(\"y'\")\n",
    "plt.title(\"Proiecție perspectivă a unui cub 3D pe planul 2D\")\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "license",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
