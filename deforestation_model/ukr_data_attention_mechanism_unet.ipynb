{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2200df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "from shapely.geometry import mapping, Point, Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"isaienkov/deforestation-in-ukraine\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf48c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/epele/.cache/kagglehub/datasets/isaienkov/deforestation-in-ukraine/versions/1\"\n",
    "df = gpd.read_file(path + \"/deforestation_labels.geojson\")\n",
    "print(\"Number of polygons:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RASTER_PATH = path + '/S2B_MSIL1C_20190611T083609_N0207_R064_T36UYA_20190611T122426/S2B_MSIL1C_20190611T083609_N0207_R064_T36UYA_20190611T122426.SAFE/GRANULE/L1C_T36UYA_A011816_20190611T084501/IMG_DATA/T36UYA_20190611T083609_TCI.jp2'\n",
    "\n",
    "with rasterio.open(RASTER_PATH, \"r\", driver='JP2OpenJPEG') as src:\n",
    "    raster_image = src.read()\n",
    "    raster_meta = src.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c442bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_image.shape\n",
    "raster_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a55acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_img = reshape_as_image(raster_image)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(raster_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning crs\n",
    "# use 4236 for tiles from this dataset\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.features import rasterize\n",
    "\n",
    "RASTER_PATH = path + '/S2B_MSIL1C_20190611T083609_N0207_R064_T36UYA_20190611T122426/S2B_MSIL1C_20190611T083609_N0207_R064_T36UYA_20190611T122426.SAFE/GRANULE/L1C_T36UYA_A011816_20190611T084501/IMG_DATA/T36UYA_20190611T083609_TCI.jp2'\n",
    "\n",
    "with rasterio.open(RASTER_PATH, \"r\", driver='JP2OpenJPEG') as src:\n",
    "    raster_image = src.read()\n",
    "    raster_meta = src.meta\n",
    "\n",
    "    raster_img = reshape_as_image(raster_image)\n",
    "\n",
    "    df.crs = {'init':'epsg:4236'}\n",
    "\n",
    "    #transforming polygons to the raster crs\n",
    "    df = df.to_crs(raster_meta['crs'])\n",
    "    # `src` is your opened Sentinel-2 raster\n",
    "\n",
    "    shapes = [(geom, 1) for geom in df.geometry]\n",
    "    mask = rasterize(\n",
    "        shapes,\n",
    "        out_shape=(src.height, src.width),\n",
    "        transform=src.transform,\n",
    "        fill=0,\n",
    "        dtype='uint8'\n",
    "    )\n",
    "    # mask now is a (H,W) array of 0/1\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d23eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d537c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "# Open one example Sentinel-2 tile to get metadata\n",
    "with rasterio.open(RASTER_PATH, \"r\", driver='JP2OpenJPEG') as src:\n",
    "    transform = src.transform\n",
    "    height, width = src.height, src.width\n",
    "\n",
    "# Prepare shapes as (geometry, value) pairs\n",
    "shapes = [(geom, 1) for geom in df.geometry]\n",
    "\n",
    "# Rasterize to binary mask\n",
    "mask = rasterize(\n",
    "    shapes,\n",
    "    out_shape=(height, width),\n",
    "    transform=transform,\n",
    "    fill=0,\n",
    "    dtype='uint8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with rasterio.open(RASTER_PATH) as src:\n",
    "    # Example for 3 bands; adjust indexes for your dataset\n",
    "    red   = src.read(1)\n",
    "    green = src.read(2)\n",
    "    blue  = src.read(3)\n",
    "\n",
    "# Stack into (H, W, 3)\n",
    "image = np.stack([red, green, blue], axis=-1).astype('float32') / 10000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9363e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a69e9f",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_path = '/home/epele/.cache/kagglehub/datasets/isaienkov/deforestation-in-ukraine/versions/1/'\n",
    "\n",
    "df = gpd.read_file(path + \"/deforestation_labels.geojson\")\n",
    "print(\"Number of polygons:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd3626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b416416",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, Conv2DTranspose, Activation,\n",
    "    MaxPooling2D, UpSampling2D,\n",
    "    add, multiply, concatenate\n",
    ")\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Activation, UpSampling2D,\n",
    "    add, multiply, Lambda\n",
    ")\n",
    "\n",
    "'''\n",
    "  Convolutional block with set parameters and activation layer after\n",
    "'''\n",
    "\n",
    "def convBlock(input, filters, kernel, kernel_init='he_normal', act='relu', transpose=False):\n",
    "  if transpose == False:\n",
    "    #conv = ZeroPadding2D((1,1))(input)\n",
    "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
    "  else:\n",
    "    #conv = ZeroPadding2D((1,1))(input)\n",
    "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
    "\n",
    "  conv = Activation(act)(conv)\n",
    "  return conv\n",
    "\n",
    "'''\n",
    "  Convolutional block with two conv layers and two activation layers\n",
    "'''\n",
    "\n",
    "def convBlock2(input, filters, kernel, kernel_init='he_normal', act='relu', transpose=False):\n",
    "  if transpose == False:\n",
    "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
    "    conv = Activation(act)(conv)\n",
    "    conv = Conv2D(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(conv)\n",
    "    conv = Activation(act)(conv)\n",
    "  else:\n",
    "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(input)\n",
    "    conv = Activation(act)(conv)\n",
    "    conv = Conv2DTranspose(filters, kernel, padding = 'same', kernel_initializer = kernel_init)(conv)\n",
    "    conv = Activation(act)(conv)\n",
    "\n",
    "  return conv\n",
    "  \n",
    "'''\n",
    "  Attention block/mechanism\n",
    "'''\n",
    "def attention_block(x, gating, inter_shape, drop_rate=0.25):\n",
    "    \"\"\"\n",
    "    x:      Tensor(shape=(batch, H, W, Cx))\n",
    "    gating: Tensor(shape=(batch, h, w, Cg))\n",
    "    inter_shape: number of filters for the attention intermediate convs\n",
    "    \"\"\"\n",
    "    # 1x1 conv + downsample x\n",
    "    theta_x = Conv2D(inter_shape, kernel_size=1, padding='same')(x)\n",
    "    theta_x = MaxPooling2D(pool_size=(2,2))(theta_x)               # -> (batch, H/2, W/2, inter_shape)\n",
    "\n",
    "    # 1x1 conv on gating signal\n",
    "    phi_g = Conv2D(inter_shape, kernel_size=1, padding='same')(gating)  # -> (batch, H/2, W/2, inter_shape)\n",
    "\n",
    "    # combine and run through activation + conv\n",
    "    add_xg = add([phi_g, theta_x])\n",
    "    act_xg = Activation('relu')(add_xg)\n",
    "    psi    = Conv2D(1, kernel_size=1, padding='same')(act_xg)       # -> (batch, H/2, W/2, 1)\n",
    "    sigmoid_xg = Activation('sigmoid')(psi)                         # same shape\n",
    "\n",
    "    # upsample mask back to xâ€™s spatial dims\n",
    "    shape_x = K.int_shape(x)\n",
    "    upsampled = UpSampling2D(\n",
    "        size=(\n",
    "            shape_x[1] // K.int_shape(sigmoid_xg)[1],\n",
    "            shape_x[2] // K.int_shape(sigmoid_xg)[2]\n",
    "        ),\n",
    "        interpolation='bilinear'\n",
    "    )(sigmoid_xg)                                                  # -> (batch, H, W, 1)\n",
    "\n",
    "    # elementwise multiply will automatically broadcast the 1-channel mask\n",
    "    y = multiply([upsampled, x])                                   # -> (batch, H, W, Cx)\n",
    "    return y\n",
    "\n",
    "'''\n",
    "  Attention U-Net model\n",
    "'''\n",
    "\n",
    "def UNetAM(trained_weights = None, input_size = (512,512,3), drop_rate = 0.25, lr=0.0001, filter_base=16):\n",
    "\n",
    "    ## Can add pretrained weights by specifying 'trained_weights'\n",
    "\n",
    "    # Input layer\n",
    "    inputs = Input(input_size, batch_size=1)\n",
    "\n",
    "    ## Contraction phase\n",
    "    conv = convBlock2(inputs, filter_base, 3)\n",
    "    #conv0 = Dropout(drop_rate)(conv0)\n",
    "\n",
    "    conv0 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv0 = convBlock2(conv0, 2 * filter_base, 3)\n",
    "\n",
    "    pool0 = MaxPooling2D(pool_size=(2, 2))(conv0)\n",
    "    conv1 = convBlock2(pool0, 4 * filter_base, 3)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = convBlock2(pool1, 8 * filter_base, 3)\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = convBlock2(pool2, 16 * filter_base, 3)\n",
    "\n",
    "    ## Expansion phase\n",
    "    up4 = (Conv2DTranspose(8 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv3))\n",
    "    merge4 = attention_block(conv2, conv3, 8 * filter_base, drop_rate) # Attention gate\n",
    "    conv4 = concatenate([up4, merge4])\n",
    "    conv4 = convBlock2(conv4, 8 * filter_base, 3)\n",
    "\n",
    "    up5 = (Conv2DTranspose(4 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv4))\n",
    "    merge5 = attention_block(conv1, conv4, 4 * filter_base, drop_rate) # Attention gate\n",
    "    conv5 = concatenate([up5, merge5])\n",
    "    conv5 = convBlock2(conv5, 4 * filter_base, 3)\n",
    "\n",
    "    up6 = (Conv2DTranspose(2 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv5))\n",
    "    merge6 = attention_block(conv0, conv5, 2 * filter_base, drop_rate) # Attention gate\n",
    "    conv6 = concatenate([up6, merge6])\n",
    "    conv6 = convBlock2(conv6, 2 * filter_base, 3)\n",
    "\n",
    "    up7 = (Conv2DTranspose(1 * filter_base, kernel_size=2, strides=2, kernel_initializer='he_normal')(conv6))\n",
    "    merge7 = attention_block(conv, conv6, 1 * filter_base, drop_rate) # Attention gate\n",
    "    conv7 = concatenate([up7, merge7])\n",
    "    conv7 = concatenate([up7, conv])\n",
    "    conv7 = convBlock2(conv7, 1 * filter_base, 3)\n",
    "\n",
    "    ## Output layer\n",
    "    out = convBlock(conv7, 1, 1, act='sigmoid')\n",
    "\n",
    "    model = Model(inputs, out)\n",
    "\n",
    "    model.compile(optimizer = Adam(learning_rate = lr), loss = binary_crossentropy, metrics = ['accuracy', 'mse'])\n",
    "\n",
    "    if trained_weights != None:\n",
    "    \tmodel.load_weights(trained_weights)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87613024",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetAM()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168bb6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "license",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
